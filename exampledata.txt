{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
...

#The more training examples you have, the better. We recommend having at least a couple hundred examples. In general, we've found that each doubling of the dataset size leads to a linear increase in model quality.

#CLI data preparation tool
"We developed a tool which validates, gives suggestions and reformats your data:"
#openai tools fine_tunes.prepare_data -f <LOCAL_FILE>


#SEE MORE DOCS AT : https://beta.openai.com/docs/guides/fine-tuning